{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_content(article_name):\n",
    "    '''Send request to wikipedia about special title'''\n",
    "    req = requests.get(f'https://en.wikipedia.org/wiki/{article_name}')\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    data = soup.find(id='bodyContent').find_all('p')\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def merge_contents(data):\n",
    "    '''Get the texts in one variable'''\n",
    "    response = ''\n",
    "    for line in data:\n",
    "        response += line.text\n",
    "    return response\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize(content):\n",
    "    '''Remove special element from the text'''\n",
    "     return re.sub(\"[\\(\\[].*?[\\)\\]\\)]\",'',content).replace(',','').replace('-', '').replace('  ','').replace('.', '').replace('\\n', '').split(' ')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def lower_collection(collection):\n",
    "    '''Turn all words to lowercase'''\n",
    "    return [i.lower() for i in collection if i.isalpha()]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_frequency(collection):\n",
    "    '''Create a dictionary and add keys as words and values as count of words in the text'''\n",
    "    data_dict = {}\n",
    "    for word in collection:\n",
    "        data_dict[word] = collection.count(word)\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_most_frequent(frequencies, n):\n",
    "    '''Print to concole most common words in specified size'''\n",
    "    sorted_list = sorted([i for i in frequencies.values()], reverse=True)\n",
    "    data_dict = {}\n",
    "    for i in sorted_list:\n",
    "        if n > 0:\n",
    "            for key in frequencies.keys():\n",
    "                if frequencies[key] == i:\n",
    "                    data_dict[key] = i\n",
    "        n -= 1\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_stop_words(words, stop_words):\n",
    "    '''Removing words from the specified stop_words'''\n",
    "    words_copy = words.copy()\n",
    "    for key in words_copy.keys():\n",
    "        if key in stop_words:\n",
    "            words.pop(key)\n",
    "    return words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def barh(data):\n",
    "    '''Print the barh chart'''\n",
    "    x = [x for x in data.keys()]\n",
    "    y = [y for y in data.values()]\n",
    "\n",
    "    # Hexadecimal color codes\n",
    "    hex_colors = [\n",
    "        '#f891a2', '#f6928e', '#f29069', '#e2913d', '#ce9839',\n",
    "        '#bd9c36', '#ad9e34', '#9da131', '#8ca632', '#72ab32',\n",
    "        '#3db133', '#00b462', '#00b180', '#00b08f', '#00af9b',\n",
    "        '#00aea5', '#00aeae', '#0fadb9', '#18aec6', '#27aed5',\n",
    "        '#58afe7', '#8eaeed', '#aeaaf0', '#c4a1ef', '#d897ee',\n",
    "        '#ed88ec', '#f684e0', '#f788cf', '#f68bc1', '#f78eb3'\n",
    "    ]\n",
    "\n",
    "    # Convert hexadecimal to RGB tuples\n",
    "    rgb_colors = [tuple(int(hex_color[i:i + 2], 16) / 255 for i in (1, 3, 5)) for hex_color in hex_colors]\n",
    "\n",
    "    plt.barh(x[::-1], y[::-1], height=0.5, color=rgb_colors)\n",
    "    plt.title('Most common 20 words in the article')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = get_content('Ozone_layer')\n",
    "merge_content = merge_contents(data)\n",
    "collection = tokenize(merge_content)\n",
    "collected = lower_collection(collection)\n",
    "stop_words = ['the', 'layer', 'ozone','of', 'and', 'in', 'to', 'is', 'a', 'an',\n",
    "              'by', 'that', 'for', 'was', 'were', 'are', 'from',\n",
    "              'at', 'it', 'as', 'be', 'these', 'on', 'with', 'this',\n",
    "              'have', 'has', 'other', 'because', 'can', 'its', 'out', 'about',\n",
    "              'into', 'or', 'over', 'all', 'most', 'which', 'less', 'while', 'above', 'than', 's', 'a', 'b']\n",
    "frequencies = count_frequency(collected)\n",
    "filtered_collection = remove_stop_words(frequencies, stop_words)\n",
    "\n",
    "most = print_most_frequent(filtered_collection, 20)\n",
    "barh(most)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
